---
title: Working with Data-Part 2-Pulling in data from Excel
author: robstilson
date: '2020-09-17'
slug: working-with-data-part-2-pulling-in-data-from-excel
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2020-09-17T18:29:46-04:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
output:
  blogdown::html_page:
    toc: true
---

# Summary

In the last [post](http://robstilson.rbind.io/post/getting-data-from-github-part-1/) we learned how to get data from GitHub. In this post I will introduce you to getting data from existing GitHub sites. We will use data sets found on Dragana Pavolovic's [GitHub page under her Data_analysis repository](https://github.com/Dragana236/Data_analysis). I discovered this from one of her blog post and it accentuates the HR data from the IBM Watson Analytics Lab. 

First in Part 1, we will download the data into Excel and save it for posterity using the `openxlsx` package. We will give each data frame its own tab or worksheet in Excel so that it is all in one place. Then, in Part 2 we will show how we upload the data to give you a feel for how you would could bring data into R from an Excel workbook that has multiple worksheets. In Part 3, we will join all of the worksheets together in R using joins from `dplyr`. Part 4, will consists of some additional EDA with all of the data joined together. We will focus on wide and tall data in Part 5 as we take the data from a single row per person to multiple rows per person as we tidy the data. Part 6 will show off some of the advantages of having your data in tall form. Part 7 will introduce the `ggplot2` package for data visualization.

## Get Packages

If you've read my post before, this may be repetitive, but this code chunk will load the necessary packages for the analysis. I've been using `pacman` for years and I encourage you to check it out as well. The `tryCatch` portion of the code will check your machine to see if `pacman` has already been installed. If it finds `pacman`, it will download it and if not it will move on. The `pacman::p_load` function is a wrapper for `library` and `require` and checks to see if the listed packages are installed. If they are not, it will attempt to install them from CRAN and/or any other repository in the `pacman` repository list (See *Description* under `?p_load` for additional information).

As a best practice, I also like to give a brief snippet of what each of the packages I'm loading will do in the analysis. This is helpful for anybody else who I send my code to, but also for myself if I need to come back to the code 6 months or more down the line.

```{r load packages, echo = FALSE, include= FALSE, warning = FALSE, message = FALSE}
#' <!-- ####################################################################################################### -->
#' <!-- ####################################################################################################### -->
#' <!-- ##################################LOADING PACKAGES##################################################### -->

tryCatch(require(pacman),finally=utils:::install.packages(pkgs='pacman',repos='http://cran.r-project.org'));
require(pacman)

# if the above doesn't work, use this code#
# tryCatch
# detach("package:pacman", unload = TRUE)
# install.packages("pacman", dependencies = TRUE)
# install.packages("pacman")

pacman::p_load(modeldata, # data sets useful for modeling packages
               dplyr, # a grammar of data manipulation
               tidyr, # tidy messy data
               readxl, # read Excel files
               ggplot2, # create elegant data visualisations using the grammar of graphics
               knitr, # a general-purpose package for dynamic report generation in R
               broom, # convert statistical objects into tidy tibbles
               purrr, # functional programming tools
               psych, #procedures for psychological, psychometric, and personality research
               conflicted, # an alternative conflict resolution strategy for like named function in different libraries
               janitor, # simple tools for examining and cleaning dirty data
               skimr, # compact and flexible summaries of data
               openxlsx, # read write and edit xlsx files
               RCurl, # general Network (HTTP/FTP/...) Client Interface for R
               tidyquant, # tidy quantitative financial analysis
               tidylog # logging for `dplyr` and `tidyr` functions
)

```

## Load packages

Here I'm explicitly calling the packages via `library`. Notice that `tidylog` is at the very end. This is necessary to load after `dplyr` so that all of the functions from `tidylog` work correctly. This is used in conjunction with the `conflicted` package. You can read more about it [here](https://github.com/elbersb/tidylog/blob/master/README.md).

```{r, echo = FALSE, include= FALSE, warning = FALSE, message = FALSE}

#' <!-- #Loading libraries -->

suppressPackageStartupMessages({
  library(modeldata)      
  library(dplyr)
  library(tidyr)
  library(readxl)
  library(ggplot2)
  library(knitr)
  library(broom)
  library(purrr)
  library(psych)
  library(conflicted)
  library(janitor)
  library(skimr)
  library(openxlsx)
  library(RCurl)
  library(tidyquant)
  library(tidylog, warn.conflicts = FALSE)
})

for (f in getNamespaceExports("tidylog")) {
    conflicted::conflict_prefer(f, "tidylog", quiet = TRUE)
}

```

```{r}
conflict_prefer("filter", "dplyr")
```


## Bring in the data

Now we will grab the data off of GitHub. We will bring it in alphabetically for no particular reason but to help us keep track of what we have and haven't downloaded. While you are here, I encourage you to check out Dragana's excellent write up of Human Resource Analytics [here](https://github.com/Dragana236/Data_analysis/blob/master/Human_resource_analytics.Rmd)
