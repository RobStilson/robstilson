---
title: Working with Data-Part 3-Joining worksheets together
author: robstilson
date: '2020-12-09'
slug: working-with-data-part-3-joining-worksheets-together
categories:
  - Joins
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2020-12-09T19:33:20-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

```{r load packages, echo = FALSE, include= FALSE, warning = FALSE, message = FALSE}
#' <!-- ####################################################################################################### -->
#' <!-- ####################################################################################################### -->
#' <!-- ##################################LOADING PACKAGES##################################################### -->

tryCatch(require(pacman),finally=utils:::install.packages(pkgs='pacman',repos='http://cran.r-project.org'));
require(pacman)

# if the above doesn't work, use this code#
# tryCatch
# detach("package:pacman", unload = TRUE)
# install.packages("pacman", dependencies = TRUE)
# install.packages("pacman")

pacman::p_load(modeldata, # data sets useful for modeling packages
               dplyr, # a grammar of data manipulation
               tidyr, # tidy messy data
               readxl, # read Excel files
               ggplot2, # create elegant data visualisations using the grammar of graphics
               knitr, # a general-purpose package for dynamic report generation in R
               broom, # convert statistical objects into tidy tibbles
               purrr, # functional programming tools
               psych, #procedures for psychological, psychometric, and personality research
               conflicted, # an alternative conflict resolution strategy for like named function in different libraries
               janitor, # simple tools for examining and cleaning dirty data
               skimr, # compact and flexible summaries of data
               openxlsx, # read write and edit xlsx files
               RCurl, # general Network (HTTP/FTP/...) Client Interface for R
               tidyquant, # tidy quantitative financial analysis
               tidylog # logging for `dplyr` and `tidyr` functions
)

```

```{r, echo = FALSE, include= FALSE, warning = FALSE, message = FALSE}

#' <!-- #Loading libraries -->

suppressPackageStartupMessages({
  library(modeldata)      
  library(dplyr)
  library(tidyr)
  library(readxl)
  library(ggplot2)
  library(knitr)
  library(broom)
  library(purrr)
  library(psych)
  library(conflicted)
  library(janitor)
  library(skimr)
  library(openxlsx)
  library(RCurl)
  library(tidyquant)
  library(tidylog, warn.conflicts = FALSE)
})

for (f in getNamespaceExports("tidylog")) {
    conflicted::conflict_prefer(f, "tidylog", quiet = TRUE)
}

```

```{r}
conflict_prefer("filter", "dplyr")
```

# Summary

In the [Part 2](http://robstilson.rbind.io/post/working-with-data-part-2-pulling-in-data-from-excel/), we covered loading Excel data from you local machine into R. Now we will cover how to join all of that data together into one worksheet.

## Bring in the data

If you haven't look at [Part 2](http://robstilson.rbind.io/post/working-with-data-part-2-pulling-in-data-from-excel/) yet, please go there now in order to get the various worksheets we are going to use directly onto your machine.

Now we will load the data from our desktop. You will need to change the directory to reflect where you stored the file. We will call the data `df`, which is short for data frame.

Remember the sheets were:

* accident
* fair_pay
* hr         
* hr_2        
* performance 
* recruitment 
* survey      
* survey_2 

We will lump all the code necessary to get the worksheets onto our machine together and then get to joining them together.

```{r}
xl_data <- "D:/Blog/Additional Data for Attrition Data Set_09_09_2020.xlsx"

tab_names <- excel_sheets(path = xl_data)

list_all <- lapply(tab_names, function(x) read_excel(path = xl_data, sheet = x))

names(list_all) <- tab_names

list2env(list_all, .GlobalEnv)
```

In your Global Environment, you should see the following:

* 8 dfs that we just uploaded

* 1 "List of 8"

* 2 Values
    - tab_names
    - xl_data
    
We're going to join all of the data from the 8 worksheets together into one larger worksheet that we will call `df`.

